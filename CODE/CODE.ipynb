{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0FC7azKE1qcT",
        "outputId": "99a85c60-6f11-4e05-bb43-1ec008004c67"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "def process_and_flag_anomalies(folder_path, threshold=0.05):\n",
        "    submission_data = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(folder_path)):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            data = pd.read_csv(file_path)\n",
        "            print(file_name)\n",
        "\n",
        "            last_sample = data.iloc[-1]\n",
        "            Q_columns = [col for col in last_sample.index if col.startswith('Q')]\n",
        "            pressure_columns = [col for col in data.columns if col.startswith('P')]\n",
        "\n",
        "            if Q_columns:\n",
        "                last_sample_q = last_sample[Q_columns]\n",
        "                q1_value = last_sample_q[\"Q1\"]\n",
        "                other_q_sum = last_sample_q.drop(\"Q1\").sum()\n",
        "\n",
        "                if q1_value - other_q_sum >= 2000:\n",
        "                    q_flags = [1] * len(pressure_columns)\n",
        "                else:\n",
        "                    q_flags = [0] * len(pressure_columns)\n",
        "            else:\n",
        "                q_flags = [0] * len(pressure_columns)\n",
        "\n",
        "            if len(data) >= 60:\n",
        "                selected_data = data[pressure_columns]\n",
        "                recent_indices = [-1, -2, -3]\n",
        "                specific_past_indices = range(-60, 0)\n",
        "\n",
        "                decrease_ratios_per_column = {col: [] for col in pressure_columns}\n",
        "\n",
        "                for recent_idx in recent_indices:\n",
        "                    if abs(recent_idx) <= len(selected_data):\n",
        "                        current_values = selected_data.iloc[recent_idx]\n",
        "                        for past_idx in specific_past_indices:\n",
        "                            if abs(past_idx) <= len(selected_data):\n",
        "                                past_values = selected_data.iloc[past_idx]\n",
        "                                decrease_ratio = (past_values - current_values) / (past_values + 1e-6)\n",
        "                                for col in pressure_columns:\n",
        "                                    decrease_ratios_per_column[col].append(decrease_ratio[col])\n",
        "\n",
        "                p_flags = [\n",
        "                    1 if any(ratio >= threshold for ratio in decrease_ratios_per_column[col]) else 0\n",
        "                    for col in pressure_columns\n",
        "                ]\n",
        "            else:\n",
        "                print(f\"파일 {file_name}에 데이터가 60개보다 적습니다. P 조건 건너뜁니다.\")\n",
        "                p_flags = [0] * len(pressure_columns)\n",
        "\n",
        "            q_p_mappings = {\n",
        "                \"Q1\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
        "                \"Q7\": [\"P7\"],\n",
        "                \"Q8\": [\"P8\"]\n",
        "            }\n",
        "            pq_flags = [0] * len(pressure_columns)\n",
        "\n",
        "            for col in pressure_columns:\n",
        "                if p_flags[pressure_columns.index(col)] == 1: \n",
        "                    related_q_keys = [q_key for q_key, p_list in q_p_mappings.items() if col in p_list]\n",
        "\n",
        "                    for q_key in related_q_keys:\n",
        "                        if q_key in Q_columns:\n",
        "                            past_q_values = data[q_key].iloc[-60:-45]\n",
        "                            condition_filtered_past = past_q_values[\n",
        "                                (past_q_values - other_q_sum) < 2000\n",
        "                            ]\n",
        "                            if len(condition_filtered_past) > 0:\n",
        "                                min_past_q = condition_filtered_past.min()\n",
        "                                current_q = data[q_key].iloc[-1]\n",
        "                                if current_q > min_past_q:\n",
        "                                    pq_flags[pressure_columns.index(col)] = 1\n",
        "\n",
        "            final_flags = [\n",
        "                1 if (q == 1 and p == 1 and pq == 1) else 0\n",
        "                for q, p, pq in zip(q_flags, p_flags, pq_flags)\n",
        "            ]\n",
        "\n",
        "            file_id = file_name.replace(\".csv\", \"\")\n",
        "            submission_data.append({\"ID\": file_id, \"flag_list\": final_flags})\n",
        "\n",
        "    return pd.DataFrame(submission_data)\n",
        "\n",
        "def process_and_flag_anomalies_D(folder_path, threshold=0.05):\n",
        "    submission_data = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(folder_path)):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            data = pd.read_csv(file_path)\n",
        "            print(file_name)\n",
        "\n",
        "            last_sample = data.iloc[-1]\n",
        "            Q_columns = [col for col in last_sample.index if col.startswith('Q')]\n",
        "            pressure_columns = [col for col in data.columns if col.startswith('P')]\n",
        "\n",
        "            if Q_columns:\n",
        "                last_sample_q = last_sample[Q_columns]\n",
        "                q1_value = last_sample_q[\"Q1\"]\n",
        "                other_q_sum = last_sample_q.drop(\"Q1\").sum()\n",
        "\n",
        "                if q1_value - other_q_sum >= 2000:\n",
        "                    q_flags = [1] * len(pressure_columns)\n",
        "                else:\n",
        "                    q_flags = [0] * len(pressure_columns)\n",
        "            else:\n",
        "                q_flags = [0] * len(pressure_columns)\n",
        "\n",
        "            if len(data) >= 60:\n",
        "                selected_data = data[pressure_columns]\n",
        "                recent_indices = [-1, -2, -3]\n",
        "                specific_past_indices = range(-60, 0)\n",
        "\n",
        "                decrease_ratios_per_column = {col: [] for col in pressure_columns}\n",
        "\n",
        "                for recent_idx in recent_indices:\n",
        "                    if abs(recent_idx) <= len(selected_data):\n",
        "                        current_values = selected_data.iloc[recent_idx]\n",
        "                        for past_idx in specific_past_indices:\n",
        "                            if abs(past_idx) <= len(selected_data):\n",
        "                                past_values = selected_data.iloc[past_idx]\n",
        "                                decrease_ratio = (past_values - current_values) / (past_values + 1e-6)\n",
        "                                for col in pressure_columns:\n",
        "                                    decrease_ratios_per_column[col].append(decrease_ratio[col])\n",
        "\n",
        "                p_flags = [\n",
        "                    1 if any(ratio >= threshold for ratio in decrease_ratios_per_column[col]) else 0\n",
        "                    for col in pressure_columns\n",
        "                ]\n",
        "            else:\n",
        "                print(f\"파일 {file_name}에 데이터가 60개보다 적습니다. P 조건 건너뜁니다.\")\n",
        "                p_flags = [0] * len(pressure_columns)\n",
        "\n",
        "            q_p_mappings = {\n",
        "                \"Q1\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
        "                \"Q3\": [\"P4\"],\n",
        "                \"Q4\": [\"P5\"],\n",
        "                \"Q5\": [\"P6\"]\n",
        "            }\n",
        "            pq_flags = [0] * len(pressure_columns)\n",
        "\n",
        "            for col in pressure_columns:\n",
        "                if p_flags[pressure_columns.index(col)] == 1:  \n",
        "                    related_q_keys = [q_key for q_key, p_list in q_p_mappings.items() if col in p_list]\n",
        "\n",
        "                    for q_key in related_q_keys:\n",
        "                        if q_key in Q_columns:\n",
        "                            past_q_values = data[q_key].iloc[-60:-45]\n",
        "                            condition_filtered_past = past_q_values[\n",
        "                                (past_q_values - other_q_sum) < 2000\n",
        "                            ]\n",
        "                            if len(condition_filtered_past) > 0:\n",
        "                                min_past_q = condition_filtered_past.min()\n",
        "                                current_q = data[q_key].iloc[-1]\n",
        "                                if current_q > min_past_q:\n",
        "                                    pq_flags[pressure_columns.index(col)] = 1\n",
        "\n",
        "            final_flags = [\n",
        "                1 if (q == 1 and p == 1 and pq == 1) else 0\n",
        "                for q, p, pq in zip(q_flags, p_flags, pq_flags)\n",
        "            ]\n",
        "\n",
        "            file_id = file_name.replace(\".csv\", \"\")\n",
        "            submission_data.append({\"ID\": file_id, \"flag_list\": final_flags})\n",
        "\n",
        "    return pd.DataFrame(submission_data)\n",
        "\n",
        "c_folder_path = 'data/test/C'  \n",
        "d_folder_path = 'data/test/D'  \n",
        "\n",
        "submission_c = process_and_flag_anomalies(c_folder_path)\n",
        "submission_d = process_and_flag_anomalies_D(d_folder_path)\n",
        "\n",
        "submission = pd.concat([submission_c, submission_d]).reset_index(drop=True)\n",
        "submission[\"flag_list\"] = submission[\"flag_list\"].apply(str)\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
